{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Purchases</th>\n",
       "      <th>B01001001</th>\n",
       "      <th>B01001002</th>\n",
       "      <th>B01001003</th>\n",
       "      <th>B01001004</th>\n",
       "      <th>B01001005</th>\n",
       "      <th>B01001006</th>\n",
       "      <th>B01001007</th>\n",
       "      <th>B01001008</th>\n",
       "      <th>B01001009</th>\n",
       "      <th>...</th>\n",
       "      <th>B19001008</th>\n",
       "      <th>B19001009</th>\n",
       "      <th>B19001010</th>\n",
       "      <th>B19001011</th>\n",
       "      <th>B19001012</th>\n",
       "      <th>B19001013</th>\n",
       "      <th>B19001014</th>\n",
       "      <th>B19001015</th>\n",
       "      <th>B19001016</th>\n",
       "      <th>B19001017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>206252</td>\n",
       "      <td>469.226965</td>\n",
       "      <td>31.432422</td>\n",
       "      <td>35.219052</td>\n",
       "      <td>33.628765</td>\n",
       "      <td>20.121017</td>\n",
       "      <td>12.610787</td>\n",
       "      <td>6.734480</td>\n",
       "      <td>6.225394</td>\n",
       "      <td>...</td>\n",
       "      <td>49.409690</td>\n",
       "      <td>53.306757</td>\n",
       "      <td>42.318307</td>\n",
       "      <td>83.167229</td>\n",
       "      <td>89.249208</td>\n",
       "      <td>102.141470</td>\n",
       "      <td>52.872330</td>\n",
       "      <td>36.440765</td>\n",
       "      <td>23.446284</td>\n",
       "      <td>21.197485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>61399</td>\n",
       "      <td>486.538869</td>\n",
       "      <td>22.899396</td>\n",
       "      <td>21.531295</td>\n",
       "      <td>27.036271</td>\n",
       "      <td>16.808091</td>\n",
       "      <td>28.355511</td>\n",
       "      <td>18.192479</td>\n",
       "      <td>13.534422</td>\n",
       "      <td>...</td>\n",
       "      <td>59.231680</td>\n",
       "      <td>50.093078</td>\n",
       "      <td>40.700626</td>\n",
       "      <td>92.612963</td>\n",
       "      <td>117.363344</td>\n",
       "      <td>113.344051</td>\n",
       "      <td>75.774243</td>\n",
       "      <td>33.000508</td>\n",
       "      <td>33.169741</td>\n",
       "      <td>24.792689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>73170</td>\n",
       "      <td>489.859232</td>\n",
       "      <td>28.905289</td>\n",
       "      <td>36.271696</td>\n",
       "      <td>28.235616</td>\n",
       "      <td>21.566216</td>\n",
       "      <td>12.218122</td>\n",
       "      <td>7.243406</td>\n",
       "      <td>7.380074</td>\n",
       "      <td>...</td>\n",
       "      <td>63.996993</td>\n",
       "      <td>47.322923</td>\n",
       "      <td>42.505211</td>\n",
       "      <td>70.420610</td>\n",
       "      <td>90.033143</td>\n",
       "      <td>98.677692</td>\n",
       "      <td>54.703249</td>\n",
       "      <td>20.125056</td>\n",
       "      <td>11.890525</td>\n",
       "      <td>16.537397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>251724</td>\n",
       "      <td>505.585483</td>\n",
       "      <td>32.054949</td>\n",
       "      <td>31.757004</td>\n",
       "      <td>28.102207</td>\n",
       "      <td>18.651380</td>\n",
       "      <td>12.080692</td>\n",
       "      <td>7.035483</td>\n",
       "      <td>7.686991</td>\n",
       "      <td>...</td>\n",
       "      <td>54.790900</td>\n",
       "      <td>48.681562</td>\n",
       "      <td>43.873381</td>\n",
       "      <td>84.717507</td>\n",
       "      <td>112.204444</td>\n",
       "      <td>127.137252</td>\n",
       "      <td>83.019904</td>\n",
       "      <td>43.731067</td>\n",
       "      <td>38.851729</td>\n",
       "      <td>40.427349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37382</td>\n",
       "      <td>495.586111</td>\n",
       "      <td>25.413301</td>\n",
       "      <td>29.318924</td>\n",
       "      <td>26.162324</td>\n",
       "      <td>19.260607</td>\n",
       "      <td>12.893906</td>\n",
       "      <td>6.580707</td>\n",
       "      <td>7.062222</td>\n",
       "      <td>...</td>\n",
       "      <td>58.883378</td>\n",
       "      <td>51.761414</td>\n",
       "      <td>47.310187</td>\n",
       "      <td>81.902582</td>\n",
       "      <td>93.793717</td>\n",
       "      <td>130.103014</td>\n",
       "      <td>71.982704</td>\n",
       "      <td>36.118530</td>\n",
       "      <td>31.603714</td>\n",
       "      <td>19.648989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Purchases  B01001001   B01001002  B01001003  B01001004  B01001005  \\\n",
       "0           22     206252  469.226965  31.432422  35.219052  33.628765   \n",
       "1            7      61399  486.538869  22.899396  21.531295  27.036271   \n",
       "2            3      73170  489.859232  28.905289  36.271696  28.235616   \n",
       "3           94     251724  505.585483  32.054949  31.757004  28.102207   \n",
       "4            0      37382  495.586111  25.413301  29.318924  26.162324   \n",
       "\n",
       "   B01001006  B01001007  B01001008  B01001009    ...      B19001008  \\\n",
       "0  20.121017  12.610787   6.734480   6.225394    ...      49.409690   \n",
       "1  16.808091  28.355511  18.192479  13.534422    ...      59.231680   \n",
       "2  21.566216  12.218122   7.243406   7.380074    ...      63.996993   \n",
       "3  18.651380  12.080692   7.035483   7.686991    ...      54.790900   \n",
       "4  19.260607  12.893906   6.580707   7.062222    ...      58.883378   \n",
       "\n",
       "   B19001009  B19001010  B19001011   B19001012   B19001013  B19001014  \\\n",
       "0  53.306757  42.318307  83.167229   89.249208  102.141470  52.872330   \n",
       "1  50.093078  40.700626  92.612963  117.363344  113.344051  75.774243   \n",
       "2  47.322923  42.505211  70.420610   90.033143   98.677692  54.703249   \n",
       "3  48.681562  43.873381  84.717507  112.204444  127.137252  83.019904   \n",
       "4  51.761414  47.310187  81.902582   93.793717  130.103014  71.982704   \n",
       "\n",
       "   B19001015  B19001016  B19001017  \n",
       "0  36.440765  23.446284  21.197485  \n",
       "1  33.000508  33.169741  24.792689  \n",
       "2  20.125056  11.890525  16.537397  \n",
       "3  43.731067  38.851729  40.427349  \n",
       "4  36.118530  31.603714  19.648989  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata = pd.read_csv('finalmaster-ratios.csv')\n",
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvariablenames = list(alldata.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B01001008',\n",
       " 'B01001009',\n",
       " 'B01001010',\n",
       " 'B01001011',\n",
       " 'B01001012',\n",
       " 'B01001013',\n",
       " 'B01001014',\n",
       " 'B01001015',\n",
       " 'B01001016',\n",
       " 'B01001017',\n",
       " 'B01001018',\n",
       " 'B01001019',\n",
       " 'B01001020',\n",
       " 'B01001021',\n",
       " 'B01001022',\n",
       " 'B01001023',\n",
       " 'B01001024',\n",
       " 'B01001025',\n",
       " 'B01001026',\n",
       " 'B01001027',\n",
       " 'B01001028',\n",
       " 'B01001029',\n",
       " 'B01001030',\n",
       " 'B01001031',\n",
       " 'B01001032',\n",
       " 'B01001033',\n",
       " 'B01001034',\n",
       " 'B01001035',\n",
       " 'B01001036',\n",
       " 'B01001037',\n",
       " 'B01001038',\n",
       " 'B01001039',\n",
       " 'B01001040',\n",
       " 'B01001041',\n",
       " 'B01001042',\n",
       " 'B01001043',\n",
       " 'B01001044',\n",
       " 'B01001045',\n",
       " 'B01001046',\n",
       " 'B01001047',\n",
       " 'B01001048',\n",
       " 'B01001049',\n",
       " 'B02001001',\n",
       " 'B02001002',\n",
       " 'B02001003',\n",
       " 'B02001004',\n",
       " 'B02001005',\n",
       " 'B02001006',\n",
       " 'B02001007',\n",
       " 'B02001008',\n",
       " 'B02001009',\n",
       " 'B02001010',\n",
       " 'B12001001',\n",
       " 'B12001002',\n",
       " 'B12001003',\n",
       " 'B12001004',\n",
       " 'B12001005',\n",
       " 'B12001006',\n",
       " 'B12001007',\n",
       " 'B12001008',\n",
       " 'B12001009',\n",
       " 'B12001010',\n",
       " 'B12001011',\n",
       " 'B12001012',\n",
       " 'B12001013',\n",
       " 'B12001014',\n",
       " 'B12001015',\n",
       " 'B12001016',\n",
       " 'B12001017',\n",
       " 'B12001018',\n",
       " 'B12001019',\n",
       " 'B13014001',\n",
       " 'B13014002',\n",
       " 'B13014003',\n",
       " 'B13014004',\n",
       " 'B13014005',\n",
       " 'B13014006',\n",
       " 'B13014007',\n",
       " 'B13014008',\n",
       " 'B13014009',\n",
       " 'B13014010',\n",
       " 'B13014011',\n",
       " 'B13014012',\n",
       " 'B13014013',\n",
       " 'B13014014',\n",
       " 'B13014015',\n",
       " 'B13014016',\n",
       " 'B13014017',\n",
       " 'B13014018',\n",
       " 'B13014019',\n",
       " 'B13014020',\n",
       " 'B13014021',\n",
       " 'B13014022',\n",
       " 'B13014023',\n",
       " 'B13014024',\n",
       " 'B13014025',\n",
       " 'B13014026',\n",
       " 'B13014027',\n",
       " 'B13015001',\n",
       " 'B13015002',\n",
       " 'B13015003',\n",
       " 'B13015004',\n",
       " 'B13015005',\n",
       " 'B13015006',\n",
       " 'B13015007',\n",
       " 'B13015008',\n",
       " 'B13015009',\n",
       " 'B13015010',\n",
       " 'B13015011',\n",
       " 'B13015012',\n",
       " 'B13015013',\n",
       " 'B13015014',\n",
       " 'B13015015',\n",
       " 'B13016001',\n",
       " 'B13016002',\n",
       " 'B13016003',\n",
       " 'B13016004',\n",
       " 'B13016005',\n",
       " 'B13016006',\n",
       " 'B13016007',\n",
       " 'B13016008',\n",
       " 'B13016009',\n",
       " 'B13016010',\n",
       " 'B13016011',\n",
       " 'B13016012',\n",
       " 'B13016013',\n",
       " 'B13016014',\n",
       " 'B13016015',\n",
       " 'B13016016',\n",
       " 'B13016017',\n",
       " 'B15002001',\n",
       " 'B15002002',\n",
       " 'B15002003',\n",
       " 'B15002004',\n",
       " 'B15002005',\n",
       " 'B15002006',\n",
       " 'B15002007',\n",
       " 'B15002008',\n",
       " 'B15002009',\n",
       " 'B15002010',\n",
       " 'B15002011',\n",
       " 'B15002012',\n",
       " 'B15002013',\n",
       " 'B15002014',\n",
       " 'B15002015',\n",
       " 'B15002016',\n",
       " 'B15002017',\n",
       " 'B15002018',\n",
       " 'B15002019',\n",
       " 'B15002020',\n",
       " 'B15002021',\n",
       " 'B15002022',\n",
       " 'B15002023',\n",
       " 'B15002024',\n",
       " 'B15002025',\n",
       " 'B15002026',\n",
       " 'B15002027',\n",
       " 'B15002028',\n",
       " 'B15002029',\n",
       " 'B15002030',\n",
       " 'B15002031',\n",
       " 'B15002032',\n",
       " 'B15002033',\n",
       " 'B15002034',\n",
       " 'B15002035',\n",
       " 'B19001001',\n",
       " 'B19001002',\n",
       " 'B19001003',\n",
       " 'B19001004',\n",
       " 'B19001005',\n",
       " 'B19001006',\n",
       " 'B19001007',\n",
       " 'B19001008',\n",
       " 'B19001009',\n",
       " 'B19001010',\n",
       " 'B19001011',\n",
       " 'B19001012',\n",
       " 'B19001013',\n",
       " 'B19001014',\n",
       " 'B19001015',\n",
       " 'B19001016',\n",
       " 'B19001017']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_drop = alldata.drop(alldata.columns[0:8],axis=1)\n",
    "after_drop.head()\n",
    "allvariablenames = list(after_drop)\n",
    "allvariablenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = after_drop\n",
    "# from B01001008\n",
    "\n",
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = alldata['# Purchases']\n",
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.739e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.736e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.579e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.483e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.383e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=5.383e-01, previous alpha=5.383e-01, with an active set of 17 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.457e-02, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=4.392e-02, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=3.408e-02, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.022e-02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.022e-02, with an active set of 100 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.022e-02, with an active set of 100 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 134 iterations, alpha=3.001e-02, previous alpha=2.940e-02, with an active set of 101 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.200e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.188e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=7.036e-01, previous alpha=6.809e-01, with an active set of 18 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.916e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.645e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.456e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.867e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.734e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.709e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.692e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.668e-01, previous alpha=1.607e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.932e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.737e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.702e-01, previous alpha=1.687e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.368e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.031e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.535e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.535e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.298e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.144e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=7.357e-01, previous alpha=6.074e-01, with an active set of 10 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.149e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.744e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.728e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.653e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 104 iterations, alpha=5.719e-02, previous alpha=5.400e-02, with an active set of 81 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.554e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.277e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.089e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.880e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 43 iterations, alpha=1.742e-01, previous alpha=1.733e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/Users/yifanli/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.datasets import make_regression\n",
    "model = LassoLarsCV(precompute=False,cv=10).fit(pred_train,tar_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01001036' 2.7861365955132507]\n",
      "['B01001037' 0.9200572652790069]\n",
      "['B01001038' 0.9459340522644333]\n",
      "['B02001005' 0.39156809216155525]\n",
      "['B13014026' 0.22056164158451835]\n",
      "['B13014027' 0.05049787197081092]\n",
      "['B19001017' 1.6062678580473928]\n"
     ]
    }
   ],
   "source": [
    "predictors_model=pd.DataFrame(allvariablenames)\n",
    "predictors_model.columns = ['label']\n",
    "predictors_model['coeff'] = model.coef_\n",
    "\n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, we all assigning all variables name to predictors_model, and then get all the coeffecient out. The for loop will print out all coefficients, which is greater then 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['B01001014' 0.8557908775529921] Males aged 40 to 44 Years.\n",
    "\"In areas where there are more Males aged 40-44, we sell more 0.8557908775529921 unit Bobo Bars.\"\n",
    "\n",
    " ['B01001036' 2.505392496591849] Females aged 30 to 34 Years.\n",
    "In areas where there are more Females aged 30-34, we sell more 2.505392496591849 unit Bobo Bars.\n",
    "\n",
    " ['B01001037' 0.8894214357013622] Females aged 35 to 39 Years.\n",
    "In areas where there are more Females aged 35-39, we sell more 0.8894214357013622 unit Bobo Bars.\n",
    "\n",
    " ['B01001038' 1.5315839680821497] Females aged 40 to 44 Years.\n",
    "In areas where there are more Females aged 40-44, we sell more 1.5315839680821497 unit Bobo Bars.\n",
    "\n",
    " ['B02001005' 0.4125408937426837] Asian Alone\n",
    "In areas where there are asian alone, we sell 0.4125408937426837 unit Bobo Bars.\n",
    "\n",
    " ['B13014026' 0.4800240326923769] Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Bachelor's Degree\n",
    "In areas where there are more females aged 15-50 years Who Had a Birth in the Past 12 Months with Bachelor's Degree, \n",
    "we sell more 0.4800240326923769 unit Bobo Bars.\n",
    "\n",
    " ['B13014027' 0.6977454940063235] Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or Professional Degree\n",
    "In areas where there are more female aged 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or Professional Degree, \n",
    "we sell more 0.6977454940063235 unit Bobo Bars.\n",
    "\n",
    " ['B13016001' 874922971.7249781] Women 15 to 50 Years Who Had a Birth in the Past 12 Months\n",
    "In areas where there are more females aged 15-50 Years Who Had a Birth in the Past 12 Months, we sell more 874922971.7249781 unit Bobo Bars.\n",
    "\n",
    " ['B19001017' 1.4834465563617387] Household with income $200,000 or More\n",
    "In areas where there are Household with income $200,000 or More, we sell more 1.4834465563617387 unit Bobo Bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would select B01001036 and B19001017 because they have higher coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data MSE\n",
      "22528.486826258624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('training data MSE')\n",
    "print(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data MSE\n",
      "41578.280293705764\n"
     ]
    }
   ],
   "source": [
    "train_test = mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('training data MSE')\n",
    "print(train_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data R-square\n",
      "0.22266652028942102\n"
     ]
    }
   ],
   "source": [
    "#r squared\n",
    "rsquared_train=model.score(pred_train,tar_train)\n",
    "print ('training data R-square')\n",
    "print(rsquared_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data R-square\n",
      "0.17529294561525344\n"
     ]
    }
   ],
   "source": [
    "rsquared_test=model.score(pred_test,tar_test)\n",
    "print ('testing data R-square')\n",
    "print(rsquared_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can observe that these two R-squares are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y interecept:\n",
      "2.758738710322305\n"
     ]
    }
   ],
   "source": [
    "print(\"y interecept:\")\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: This is not a great method to predict sales. Because census data cannot reflect the result very well. \n",
    "To be specific, training data MSE is huge, but R-square is very small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question #6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y intercept is 2.758738710322305, and the baseline sales number is 2.758738710322305."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
